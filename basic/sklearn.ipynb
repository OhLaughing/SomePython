{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "use sklearn\n",
      "[[-1.0856306   0.99734545  0.2829785  -1.50629471]\n",
      " [-0.57860025  1.65143654 -2.42667924 -0.42891263]\n",
      " [ 1.26593626 -0.8667404  -0.67888615 -0.09470897]\n",
      " [ 1.49138963 -0.638902   -0.44398196 -0.43435128]\n",
      " [ 2.20593008  2.18678609  1.0040539   0.3861864 ]\n",
      " [ 0.73736858  1.49073203 -0.93583387  1.17582904]\n",
      " [-1.25388067 -0.6377515   0.9071052  -1.4286807 ]\n",
      " [-0.14006872 -0.8617549  -0.25561937 -2.79858911]\n",
      " [-1.7715331  -0.69987723  0.92746243 -0.17363568]\n",
      " [ 0.00284592  0.68822271 -0.87953634  0.28362732]]\n",
      "[[-0.94511643  0.58665507  0.5223171  -0.93064483]\n",
      " [-0.53659117  1.16247784 -2.13366794  0.06768082]\n",
      " [ 0.9495916  -1.05437488 -0.42049501  0.3773612 ]\n",
      " [ 1.13124423 -0.85379954 -0.19024378  0.06264126]\n",
      " [ 1.70696485  1.63376764  1.22910949  0.8229693 ]\n",
      " [ 0.52371324  1.02100318 -0.67235312  1.55466934]\n",
      " [-1.08067913 -0.85278672  1.13408114 -0.858726  ]\n",
      " [-0.18325687 -1.04998594 -0.00561227 -2.1281129 ]\n",
      " [-1.49776284 -0.9074785   1.15403514  0.30422599]\n",
      " [-0.06810748  0.31452186 -0.61717074  0.72793583]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "np.random.seed(123)\n",
    "print('use sklearn')\n",
    "# 注：shape of data: [n_samples, n_features]\n",
    "data = np.random.randn(10, 4)\n",
    "print(data)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(data)\n",
    "trans_data = scaler.transform(data)\n",
    "print(trans_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出均值和方差，通过numpy的方法也可以获取均值和方差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08737571  0.33094968 -0.24989369 -0.50195303]\n",
      "[1.54038781 1.29032409 1.04082479 1.16464894]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.08737571  0.33094968 -0.24989369 -0.50195303]\n",
      "[1.54038781 1.29032409 1.04082479 1.16464894]\n"
     ]
    }
   ],
   "source": [
    "print(data.mean(axis=0))\n",
    "print(data.var(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.94511643  0.58665507  0.5223171  -0.93064483]\n",
      " [-0.53659117  1.16247784 -2.13366794  0.06768082]\n",
      " [ 0.9495916  -1.05437488 -0.42049501  0.3773612 ]\n",
      " [ 1.13124423 -0.85379954 -0.19024378  0.06264126]\n",
      " [ 1.70696485  1.63376764  1.22910949  0.8229693 ]\n",
      " [ 0.52371324  1.02100318 -0.67235312  1.55466934]\n",
      " [-1.08067913 -0.85278672  1.13408114 -0.858726  ]\n",
      " [-0.18325687 -1.04998594 -0.00561227 -2.1281129 ]\n",
      " [-1.49776284 -0.9074785   1.15403514  0.30422599]\n",
      " [-0.06810748  0.31452186 -0.61717074  0.72793583]]\n"
     ]
    }
   ],
   "source": [
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过scaler.transform得到的标准化数据，其实和下面的方法一样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94511643,  0.58665507,  0.5223171 , -0.93064483],\n",
       "       [-0.53659117,  1.16247784, -2.13366794,  0.06768082],\n",
       "       [ 0.9495916 , -1.05437488, -0.42049501,  0.3773612 ],\n",
       "       [ 1.13124423, -0.85379954, -0.19024378,  0.06264126],\n",
       "       [ 1.70696485,  1.63376764,  1.22910949,  0.8229693 ],\n",
       "       [ 0.52371324,  1.02100318, -0.67235312,  1.55466934],\n",
       "       [-1.08067913, -0.85278672,  1.13408114, -0.858726  ],\n",
       "       [-0.18325687, -1.04998594, -0.00561227, -2.1281129 ],\n",
       "       [-1.49776284, -0.9074785 ,  1.15403514,  0.30422599],\n",
       "       [-0.06810748,  0.31452186, -0.61717074,  0.72793583]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data-scaler.mean_)/np.sqrt(scaler.var_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过numpy运算也可以"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.94511643,  0.58665507,  0.5223171 , -0.93064483],\n",
       "       [-0.53659117,  1.16247784, -2.13366794,  0.06768082],\n",
       "       [ 0.9495916 , -1.05437488, -0.42049501,  0.3773612 ],\n",
       "       [ 1.13124423, -0.85379954, -0.19024378,  0.06264126],\n",
       "       [ 1.70696485,  1.63376764,  1.22910949,  0.8229693 ],\n",
       "       [ 0.52371324,  1.02100318, -0.67235312,  1.55466934],\n",
       "       [-1.08067913, -0.85278672,  1.13408114, -0.858726  ],\n",
       "       [-0.18325687, -1.04998594, -0.00561227, -2.1281129 ],\n",
       "       [-1.49776284, -0.9074785 ,  1.15403514,  0.30422599],\n",
       "       [-0.06810748,  0.31452186, -0.61717074,  0.72793583]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data-np.mean(data,axis=0))/np.std(data,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "[1. 2.]\n",
      "3.0000000000000018\n",
      "[16.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = 1 * x_0 + 2 * x_1 + 3\n",
    "y = np.dot(X, np.array([1, 2])) + 3\n",
    "reg = LinearRegression().fit(X, y)\n",
    "print(reg.score(X, y))\n",
    "\n",
    "print(reg.coef_)\n",
    "\n",
    "print(reg.intercept_)\n",
    "\n",
    "print(reg.predict(np.array([[3, 5]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_regression(n_samples=1000, random_state=0)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "print(lr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StandardScaler(copy=True, with_mean=True, with_std=True)\n",
      "[[-1. -1.]\n",
      " [-1. -1.]\n",
      " [ 1.  1.]\n",
      " [ 1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
    "scaler = StandardScaler()\n",
    "print(scaler.fit(data))\n",
    "print(scaler.transform(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.mean_)\n",
    "print(scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "期望和标准差，可以通过numpy的mean和var方法获取,scaler.transform获取标准化数据，如果自己计算，为(data-scaler.mean_)/np.sqrt(scaler.var_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
